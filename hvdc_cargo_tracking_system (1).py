#!/usr/bin/env python3
"""
HVDC-ADOPT í™”ë¬¼ ì¶”ì  ì‹œìŠ¤í…œ
MACHO-GPT v3.4-mini - Cargo Tracking Intelligence

ê¸°ëŠ¥:
- HVDC-ADOPT-XXX-XXXX ì¼€ì´ìŠ¤ë³„ ETA/ATA ì¶”ì 
- í˜„ì¥ ì…ê³  ë‚ ì§œ (SHU/MIR/DAS/AGI) ëª¨ë‹ˆí„°ë§
- í™”ë¬¼ ìƒíƒœ (STATUS) ìë™ ë¶„ë¥˜
- ì´ë©”ì¼ ì—°ë™ ì¶”ì 
- ì˜¨í†¨ë¡œì§€ ë§¤í•‘ í†µí•©
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import json
import re
from typing import Dict, List, Tuple


class HVDCCargoTracker:
    """HVDC-ADOPT í™”ë¬¼ ì¶”ì  ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 status_file: str = "HVDC PJT/hvdc_macho_gpt/HVDC STATUS/data/HVDC STATUS(20250810).xlsx",
                 email_json: str = "hvdc_emails_structured.json"):
        self.status_file = status_file
        self.email_json = email_json
        self.df_status = None
        self.df_emails = None
        self.tracking_data = []
        
        # ì‚¬ì´íŠ¸ ì»¬ëŸ¼
        self.site_columns = ['SHU', 'MIR', 'DAS', 'AGI']
        
        # ì°½ê³  ì»¬ëŸ¼
        self.warehouse_columns = [
            'DSV\nIndoor', 'DSV\nOutdoor', 'DSV\nMZD', 
            'JDN\nMZD', 'JDN\nWaterfront', 'MOSB', 
            'AAA Storage', 'ZENER (WH)', 'Hauler DG Storage', 'Vijay Tanks'
        ]
        
        # ìƒíƒœ ì •ì˜
        self.status_map = {
            'NOT_SHIPPED': 'ë¯¸ì¶œê³ ',
            'IN_TRANSIT': 'ìš´ì†¡ì¤‘',
            'PORT_ARRIVAL': 'í•­êµ¬ë„ì°©',
            'CUSTOMS': 'í†µê´€ì¤‘',
            'WAREHOUSE': 'ì°½ê³ ë³´ê´€',
            'SITE_DELIVERED': 'í˜„ì¥ì¸ë„',
            'DELAYED': 'ì§€ì—°',
            'UNKNOWN': 'ìƒíƒœë¶ˆëª…'
        }
    
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("="*70)
        print("ğŸ“¦ HVDC-ADOPT í™”ë¬¼ ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print("="*70)
        
        # STATUS íŒŒì¼ ë¡œë“œ
        print(f"\nğŸ“‚ STATUS íŒŒì¼ ë¡œë“œ: {self.status_file}")
        try:
            self.df_status = pd.read_excel(self.status_file)
            print(f"   âœ… {len(self.df_status):,}ê±´ì˜ í™”ë¬¼ ë°ì´í„° ë¡œë“œ")
            
            # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
            date_columns = ['ETD', 'ATD', 'ETA', 'ATA '] + self.site_columns + self.warehouse_columns
            for col in date_columns:
                if col in self.df_status.columns:
                    self.df_status[col] = pd.to_datetime(self.df_status[col], errors='coerce')
            
            print(f"   ğŸ“… ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜ ì™„ë£Œ")
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
            return False
        
        # ì´ë©”ì¼ ë°ì´í„° ë¡œë“œ
        if Path(self.email_json).exists():
            print(f"\nğŸ“§ ì´ë©”ì¼ ë°ì´í„° ë¡œë“œ: {self.email_json}")
            try:
                with open(self.email_json, 'r', encoding='utf-8') as f:
                    email_data = json.load(f)
                    self.df_emails = pd.DataFrame(email_data['emails'])
                    print(f"   âœ… {len(self.df_emails):,}ê±´ì˜ ì´ë©”ì¼ ë°ì´í„° ë¡œë“œ")
            except Exception as e:
                print(f"   âš ï¸  ì´ë©”ì¼ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return True
    
    def determine_status(self, row: pd.Series) -> str:
        """í™”ë¬¼ ìƒíƒœ ê²°ì •"""
        # 1. í˜„ì¥ ì¸ë„ í™•ì¸
        for site in self.site_columns:
            if pd.notna(row.get(site)):
                return 'SITE_DELIVERED'
        
        # 2. ì°½ê³  ë³´ê´€ í™•ì¸
        for warehouse in self.warehouse_columns:
            if pd.notna(row.get(warehouse)):
                return 'WAREHOUSE'
        
        # 3. í†µê´€ í™•ì¸
        if pd.notna(row.get('Customs\nStart')):
            if pd.isna(row.get('Customs\nClose')):
                return 'CUSTOMS'
        
        # 4. í•­êµ¬ ë„ì°© í™•ì¸
        if pd.notna(row.get('ATA ')):
            return 'PORT_ARRIVAL'
        
        # 5. ìš´ì†¡ ì¤‘ í™•ì¸
        if pd.notna(row.get('ATD')) or pd.notna(row.get('ETD')):
            # ì§€ì—° ì²´í¬
            eta = row.get('ETA')
            if pd.notna(eta) and eta < pd.Timestamp.now():
                if pd.isna(row.get('ATA ')):
                    return 'DELAYED'
            return 'IN_TRANSIT'
        
        # 6. ë¯¸ì¶œê³ 
        if pd.isna(row.get('ETD')) and pd.isna(row.get('ATD')):
            return 'NOT_SHIPPED'
        
        return 'UNKNOWN'
    
    def calculate_lead_time(self, row: pd.Series) -> Dict:
        """ë¦¬ë“œíƒ€ì„ ê³„ì‚°"""
        lead_times = {}
        
        # ATD -> ATA
        if pd.notna(row.get('ATD')) and pd.notna(row.get('ATA ')):
            lead_times['shipping_days'] = (row['ATA '] - row['ATD']).days
        
        # ATA -> ì²« ë²ˆì§¸ ì‚¬ì´íŠ¸
        ata = row.get('ATA ')
        if pd.notna(ata):
            for site in self.site_columns:
                site_date = row.get(site)
                if pd.notna(site_date):
                    lead_times[f'port_to_{site.lower()}'] = (site_date - ata).days
                    break
        
        # ì´ ë¦¬ë“œíƒ€ì„ (ATD -> ìµœì¢… ì‚¬ì´íŠ¸)
        atd = row.get('ATD')
        if pd.notna(atd):
            site_dates = [row.get(s) for s in self.site_columns if pd.notna(row.get(s))]
            if site_dates:
                final_site_date = max(site_dates)
                lead_times['total_days'] = (final_site_date - atd).days
        
        return lead_times
    
    def get_current_location(self, row: pd.Series) -> str:
        """í˜„ì¬ ìœ„ì¹˜ ê²°ì •"""
        # ìµœê·¼ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ìœ„ì¹˜ ê²°ì •
        location_dates = {}
        
        # ì‚¬ì´íŠ¸
        for site in self.site_columns:
            if pd.notna(row.get(site)):
                location_dates[site] = row[site]
        
        # ì°½ê³ 
        for warehouse in self.warehouse_columns:
            if pd.notna(row.get(warehouse)):
                warehouse_name = warehouse.replace('\n', ' ').strip()
                location_dates[warehouse_name] = row[warehouse]
        
        if location_dates:
            latest_location = max(location_dates.items(), key=lambda x: x[1])
            return latest_location[0]
        
        # ìœ„ì¹˜ ì—†ìœ¼ë©´ ìƒíƒœ ê¸°ë°˜
        if pd.notna(row.get('ATA ')):
            return 'PORT'
        elif pd.notna(row.get('ATD')):
            return 'SEA/AIR'
        else:
            return 'ORIGIN'
    
    def find_related_emails(self, case_no: str) -> List[Dict]:
        """ê´€ë ¨ ì´ë©”ì¼ ì°¾ê¸°"""
        if self.df_emails is None:
            return []
        
        related = []
        # ì¼€ì´ìŠ¤ ë²ˆí˜¸ë¡œ í•„í„°ë§
        case_pattern = case_no.replace('HVDC-ADOPT-', '')
        
        for idx, email in self.df_emails.iterrows():
            subject = str(email.get('subject', '')).upper()
            if case_pattern in subject or case_no in subject:
                related.append({
                    'date': email.get('received_time'),
                    'sender': email.get('sender_name'),
                    'subject': email.get('subject'),
                    'type': email.get('email_type')
                })
        
        return related
    
    def process_tracking_data(self):
        """í™”ë¬¼ ì¶”ì  ë°ì´í„° ì²˜ë¦¬"""
        print("\nğŸ”„ í™”ë¬¼ ì¶”ì  ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        for idx, row in self.df_status.iterrows():
            if idx % 100 == 0:
                print(f"   ì§„í–‰ë¥ : {idx}/{len(self.df_status)} ({idx/len(self.df_status)*100:.1f}%)")
            
            case_no = row.get('HVDC CODE')
            if pd.isna(case_no) or not str(case_no).startswith('HVDC-ADOPT-'):
                continue
            
            # ìƒíƒœ ê²°ì •
            status = self.determine_status(row)
            
            # ë¦¬ë“œíƒ€ì„ ê³„ì‚°
            lead_times = self.calculate_lead_time(row)
            
            # í˜„ì¬ ìœ„ì¹˜
            current_location = self.get_current_location(row)
            
            # ê´€ë ¨ ì´ë©”ì¼
            related_emails = self.find_related_emails(case_no)
            
            # ì¶”ì  ë°ì´í„° ìƒì„±
            tracking_info = {
                'case_no': case_no,
                'status': status,
                'status_kr': self.status_map[status],
                'current_location': current_location,
                
                # ê¸°ë³¸ ì •ë³´
                'vendor': row.get('VENDOR'),
                'description': row.get('SUB DESCRIPTION'),
                'bl_no': row.get('B/L No./\nAWB No.'),
                'vessel': row.get('VESSEL NAME/\nFLIGHT No.'),
                
                # ë‚ ì§œ ì •ë³´
                'etd': row.get('ETD'),
                'atd': row.get('ATD'),
                'eta': row.get('ETA'),
                'ata': row.get('ATA '),
                
                # í˜„ì¥ ì…ê³  ë‚ ì§œ
                'site_shu': row.get('SHU'),
                'site_mir': row.get('MIR'),
                'site_das': row.get('DAS'),
                'site_agi': row.get('AGI'),
                
                # ë¦¬ë“œíƒ€ì„
                'lead_times': lead_times,
                
                # íŒ¨í‚¤ì§€ ì •ë³´
                'pkg': row.get('PKG'),
                'cbm': row.get('CBM'),
                'gwt': row.get('GWT\n(KG)'),
                
                # ê´€ë ¨ ì´ë©”ì¼
                'related_emails_count': len(related_emails),
                'latest_email': related_emails[0] if related_emails else None
            }
            
            self.tracking_data.append(tracking_info)
        
        print(f"   âœ… {len(self.tracking_data):,}ê±´ì˜ HVDC-ADOPT í™”ë¬¼ ì²˜ë¦¬ ì™„ë£Œ")
    
    def generate_summary_report(self, output_file: str = "hvdc_cargo_tracking_report.md"):
        """ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        print(f"\nğŸ“Š ì¶”ì  ë¦¬í¬íŠ¸ ìƒì„±: {output_file}")
        
        df = pd.DataFrame(self.tracking_data)
        
        md = []
        md.append("# HVDC-ADOPT í™”ë¬¼ ì¶”ì  ë¦¬í¬íŠ¸")
        md.append("\n**MACHO-GPT v3.4-mini** | Samsung C&T Logistics Ã— ADNOCÂ·DSV")
        md.append(f"\n**ìƒì„±ì¼:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        md.append(f"\n**ì´ í™”ë¬¼:** {len(df):,}ê±´")
        md.append(f"\n---\n")
        
        # ìƒíƒœë³„ í†µê³„
        md.append("## ğŸ“Š í™”ë¬¼ ìƒíƒœ ë¶„í¬")
        status_counts = df['status_kr'].value_counts()
        for status, count in status_counts.items():
            percentage = count / len(df) * 100
            bar = 'â–ˆ' * int(percentage / 2)
            md.append(f"- **{status}:** {count:,}ê±´ ({percentage:.1f}%) {bar}")
        
        # ì‚¬ì´íŠ¸ë³„ ì¸ë„ í˜„í™©
        md.append("\n## ğŸ—ï¸ ì‚¬ì´íŠ¸ë³„ ì¸ë„ í˜„í™©")
        for site in ['site_shu', 'site_mir', 'site_das', 'site_agi']:
            delivered = df[site].notna().sum()
            site_name = site.replace('site_', '').upper()
            md.append(f"- **{site_name}:** {delivered:,}ê±´ ì¸ë„ ì™„ë£Œ")
        
        # ì§€ì—° í™”ë¬¼
        delayed = df[df['status'] == 'DELAYED']
        if len(delayed) > 0:
            md.append(f"\n## âš ï¸ ì§€ì—° í™”ë¬¼ ({len(delayed)}ê±´)")
            for idx, row in delayed.head(10).iterrows():
                eta = row['eta']
                days_delayed = (pd.Timestamp.now() - eta).days if pd.notna(eta) else 0
                md.append(f"- **{row['case_no']}** - ETA: {eta.strftime('%Y-%m-%d') if pd.notna(eta) else 'N/A'} ({days_delayed}ì¼ ì§€ì—°)")
        
        # ìµœê·¼ ì¸ë„ í™”ë¬¼
        md.append("\n## ğŸ“¦ ìµœê·¼ í˜„ì¥ ì¸ë„ (ìµœê·¼ 10ê±´)")
        delivered_cargos = df[df['status'] == 'SITE_DELIVERED'].copy()
        if len(delivered_cargos) > 0:
            # ê°€ì¥ ìµœê·¼ ì‚¬ì´íŠ¸ ë‚ ì§œ ì°¾ê¸°
            site_dates = delivered_cargos[['site_shu', 'site_mir', 'site_das', 'site_agi']].apply(
                lambda row: row.dropna().max() if row.notna().any() else pd.NaT, axis=1
            )
            delivered_cargos['latest_delivery'] = site_dates
            delivered_cargos = delivered_cargos.sort_values('latest_delivery', ascending=False)
            
            for idx, row in delivered_cargos.head(10).iterrows():
                delivery_date = row['latest_delivery']
                md.append(f"- **{row['case_no']}** â†’ {row['current_location']} ({delivery_date.strftime('%Y-%m-%d') if pd.notna(delivery_date) else 'N/A'})")
        
        # ì´ë©”ì¼ ì—°ë™ í†µê³„
        md.append("\n## ğŸ“§ ì´ë©”ì¼ ì—°ë™ í†µê³„")
        with_emails = df[df['related_emails_count'] > 0]
        md.append(f"- **ì´ë©”ì¼ ì¶”ì  ê°€ëŠ¥:** {len(with_emails):,}ê±´ ({len(with_emails)/len(df)*100:.1f}%)")
        md.append(f"- **ì´ë©”ì¼ ì—†ìŒ:** {len(df) - len(with_emails):,}ê±´")
        
        # ë¦¬ë“œíƒ€ì„ ë¶„ì„
        md.append("\n## â±ï¸ ë¦¬ë“œíƒ€ì„ ë¶„ì„")
        shipping_days = []
        total_days = []
        for lead_time in df['lead_times']:
            if 'shipping_days' in lead_time:
                shipping_days.append(lead_time['shipping_days'])
            if 'total_days' in lead_time:
                total_days.append(lead_time['total_days'])
        
        if shipping_days:
            md.append(f"- **í‰ê·  í•´ìƒìš´ì†¡ ì¼ìˆ˜:** {np.mean(shipping_days):.1f}ì¼")
            md.append(f"- **ìµœì†Œ/ìµœëŒ€:** {min(shipping_days)}ì¼ / {max(shipping_days)}ì¼")
        
        if total_days:
            md.append(f"- **í‰ê·  ì´ ë¦¬ë“œíƒ€ì„:** {np.mean(total_days):.1f}ì¼")
            md.append(f"- **ìµœì†Œ/ìµœëŒ€:** {min(total_days)}ì¼ / {max(total_days)}ì¼")
        
        md.append("\n---")
        md.append("\n*Generated by HVDC Cargo Tracking System*")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(md))
        
        print(f"   âœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ")
    
    def export_to_excel(self, output_file: str = "hvdc_cargo_tracking.xlsx"):
        """Excel ì¶”ì  íŒŒì¼ ìƒì„±"""
        print(f"\nğŸ’¾ Excel ì¶”ì  íŒŒì¼ ìƒì„±: {output_file}")
        
        df = pd.DataFrame(self.tracking_data)
        
        # ë‚ ì§œ ì»¬ëŸ¼ í¬ë§·íŒ…
        date_cols = ['etd', 'atd', 'eta', 'ata', 'site_shu', 'site_mir', 'site_das', 'site_agi']
        for col in date_cols:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d')
        
        # ë¦¬ë“œíƒ€ì„ ì»¬ëŸ¼ í™•ì¥
        df['shipping_days'] = df['lead_times'].apply(lambda x: x.get('shipping_days', '') if isinstance(x, dict) else '')
        df['total_days'] = df['lead_times'].apply(lambda x: x.get('total_days', '') if isinstance(x, dict) else '')
        
        # ì»¬ëŸ¼ ì œê±°
        df = df.drop(['lead_times', 'latest_email'], axis=1, errors='ignore')
        
        # Excel ì €ì¥
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Cargo Tracking', index=False)
            
            # ìš”ì•½ ì‹œíŠ¸
            summary_df = df.groupby('status_kr').agg({
                'case_no': 'count',
                'pkg': 'sum',
                'cbm': 'sum',
                'gwt': 'sum'
            }).reset_index()
            summary_df.columns = ['ìƒíƒœ', 'í™”ë¬¼ ìˆ˜', 'ì´ PKG', 'ì´ CBM', 'ì´ ì¤‘ëŸ‰(KG)']
            summary_df.to_excel(writer, sheet_name='Summary', index=False)
        
        print(f"   âœ… Excel íŒŒì¼ ì €ì¥ ì™„ë£Œ")
    
    def generate_ontology_ttl(self, output_file: str = "hvdc_cargo_tracking_ontology.ttl"):
        """ì˜¨í†¨ë¡œì§€ TTL íŒŒì¼ ìƒì„±"""
        print(f"\nğŸ“ ì˜¨í†¨ë¡œì§€ TTL ìƒì„±: {output_file}")
        
        ttl_lines = []
        
        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤
        ttl_lines.append("@prefix cargo: <http://samsung.com/hvdc/cargo#> .")
        ttl_lines.append("@prefix ex: <http://samsung.com/project-logistics#> .")
        ttl_lines.append("@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .")
        ttl_lines.append("")
        
        # í´ë˜ìŠ¤ ì •ì˜
        ttl_lines.append("# Cargo Tracking Classes")
        ttl_lines.append("cargo:Cargo a rdfs:Class ;")
        ttl_lines.append('    rdfs:label "í™”ë¬¼"@ko .')
        ttl_lines.append("")
        
        ttl_lines.append("cargo:CargoStatus a rdfs:Class ;")
        ttl_lines.append('    rdfs:label "í™”ë¬¼ ìƒíƒœ"@ko .')
        ttl_lines.append("")
        
        # ì†ì„± ì •ì˜
        ttl_lines.append("cargo:hasStatus a rdf:Property ;")
        ttl_lines.append('    rdfs:domain cargo:Cargo ;')
        ttl_lines.append('    rdfs:range cargo:CargoStatus .')
        ttl_lines.append("")
        
        ttl_lines.append("cargo:hasETA a rdf:Property ;")
        ttl_lines.append('    rdfs:domain cargo:Cargo ;')
        ttl_lines.append('    rdfs:range xsd:dateTime .')
        ttl_lines.append("")
        
        ttl_lines.append("cargo:hasATA a rdf:Property ;")
        ttl_lines.append('    rdfs:domain cargo:Cargo ;')
        ttl_lines.append('    rdfs:range xsd:dateTime .')
        ttl_lines.append("")
        
        ttl_lines.append("cargo:deliveredToSite a rdf:Property ;")
        ttl_lines.append('    rdfs:domain cargo:Cargo ;')
        ttl_lines.append('    rdfs:range ex:Site .')
        ttl_lines.append("")
        
        # ìƒ˜í”Œ ì¸ìŠ¤í„´ìŠ¤ (50ê°œ)
        ttl_lines.append("# Cargo Instances (Sample 50)")
        for data in self.tracking_data[:50]:
            case_id = data['case_no'].replace('HVDC-ADOPT-', 'Cargo_')
            
            ttl_lines.append(f"cargo:{case_id} a cargo:Cargo ;")
            ttl_lines.append(f'    cargo:caseNumber "{data["case_no"]}" ;')
            ttl_lines.append(f'    cargo:hasStatus cargo:{data["status"]} ;')
            ttl_lines.append(f'    cargo:currentLocation "{data["current_location"]}" ;')
            
            if pd.notna(data.get('eta')):
                ttl_lines.append(f'    cargo:hasETA "{data["eta"]}"^^xsd:dateTime ;')
            if pd.notna(data.get('ata')):
                ttl_lines.append(f'    cargo:hasATA "{data["ata"]}"^^xsd:dateTime ;')
            
            # ì‚¬ì´íŠ¸ ì¸ë„ ì •ë³´
            for site in ['shu', 'mir', 'das', 'agi']:
                site_date = data.get(f'site_{site}')
                if pd.notna(site_date):
                    ttl_lines.append(f'    cargo:deliveredToSite ex:Site_{site.upper()} ;')
                    ttl_lines.append(f'    cargo:deliveryDate_{site.upper()} "{site_date}"^^xsd:dateTime ;')
            
            ttl_lines[-1] = ttl_lines[-1].rstrip(' ;') + ' .'
            ttl_lines.append("")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(ttl_lines))
        
        print(f"   âœ… TTL íŒŒì¼ ì €ì¥ ì™„ë£Œ")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    tracker = HVDCCargoTracker()
    
    # ë°ì´í„° ë¡œë“œ
    if not tracker.load_data():
        return
    
    # ì¶”ì  ë°ì´í„° ì²˜ë¦¬
    tracker.process_tracking_data()
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    tracker.generate_summary_report()
    
    # Excel ë‚´ë³´ë‚´ê¸°
    tracker.export_to_excel()
    
    # ì˜¨í†¨ë¡œì§€ ìƒì„±
    tracker.generate_ontology_ttl()
    
    print("\n" + "="*70)
    print("âœ… HVDC-ADOPT í™”ë¬¼ ì¶”ì  ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!")
    print("="*70)
    print("\nğŸ“‚ ìƒì„±ëœ íŒŒì¼:")
    print("   â€¢ hvdc_cargo_tracking_report.md - ì¶”ì  ë¦¬í¬íŠ¸")
    print("   â€¢ hvdc_cargo_tracking.xlsx - Excel ì¶”ì  íŒŒì¼")
    print("   â€¢ hvdc_cargo_tracking_ontology.ttl - ì˜¨í†¨ë¡œì§€ ë§¤í•‘")


if __name__ == "__main__":
    main()



