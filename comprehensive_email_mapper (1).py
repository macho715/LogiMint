#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HVDC í”„ë¡œì íŠ¸ ì¢…í•© ì´ë©”ì¼ ë§¤í•‘ ì‹œìŠ¤í…œ
ëª¨ë“  í´ë” ìŠ¤ìº” í›„ íŒŒì¼ ì œëª©ê³¼ ë‚ ì§œë³„ ë§¤í•‘ìœ¼ë¡œ ì „ì²´ í”„ë¡œì íŠ¸ ìœ ê¸°ì  ì—°ê²°
"""

import os
import re
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
import logging
from typing import Dict, List, Tuple, Optional
from collections import defaultdict, Counter
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('comprehensive_mapping.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ComprehensiveEmailMapper:
    """HVDC í”„ë¡œì íŠ¸ ì¢…í•© ì´ë©”ì¼ ë§¤í•‘ í´ë˜ìŠ¤"""
    
    def __init__(self, email_root_path: str):
        self.email_root_path = Path(email_root_path)
        self.scan_results = {}
        self.project_connections = defaultdict(list)
        self.timeline_data = []
        self.vendor_network = defaultdict(list)
        self.site_network = defaultdict(list)
        self.case_network = defaultdict(list)
        
        # HVDC ì¼€ì´ìŠ¤ ë²ˆí˜¸ ì¶”ì¶œ íŒ¨í„´
        self.case_patterns = {
            'pattern1': r'HVDC-ADOPT-([A-Z]+)-([A-Z0-9\-]+)',
            'pattern2': r'HVDC-([A-Z]+)-([A-Z]+)-([A-Z0-9\-]+)',
            'pattern3_outer': r'\(([^\)]+)\)',
            'pattern3_inner': r'([A-Z]+)-([0-9]+(?:-[0-9A-Z]+)?)',
            'pattern4': r'\[HVDC-AGI\].*?(JPTW-(\d+))\s*/\s*(GRM-(\d+))',
            'pattern5': r':\s*([A-Z]+-[A-Z]+-[A-Z]+\d+-[A-Z]+\d+)'
        }
        
        # ë²¤ë” ì½”ë“œ ë§¤í•‘
        self.vendor_codes = {
            'HE': 'Hitachi Energy',
            'SCT': 'Samsung C&T', 
            'SIM': 'Siemens',
            'MOSB': 'MOSB',
            'ALS': 'ALS',
            'JPTW': 'JPTW',
            'GRM': 'GRM',
            'ZEN': 'ZENER',
            'DAS': 'DAS Site',
            'AGI': 'AGI Site',
            'MIR': 'MIR Site',
            'MIRFA': 'MIRFA Site',
            'GHALLAN': 'GHALLAN Site'
        }
        
        # ì‚¬ì´íŠ¸ ì½”ë“œ ë§¤í•‘
        self.site_codes = {
            'DAS': 'ë³€ì „ì†Œ',
            'AGI': 'ê³¨ì¬ ì €ì¥ì†Œ', 
            'MIR': 'ì¤‘ê°„ ë³€ì „ì†Œ',
            'MIRFA': 'ë³´ì¡° ë³€ì „ì†Œ',
            'GHALLAN': 'ì‚¬ë§‰ ì‚¬ì´íŠ¸'
        }
        
        # í”„ë¡œì íŠ¸ ë‹¨ê³„ë³„ í‚¤ì›Œë“œ
        self.project_phases = {
            'procurement': ['LPO', 'PO', 'Purchase Order', 'Procurement', 'Order'],
            'shipping': ['Shipping', 'Delivery', 'Container', 'CNTR', 'LCT', 'Vessel'],
            'customs': ['Customs', 'Clearance', 'Import', 'Export', 'Duty'],
            'logistics': ['Logistics', 'Transport', 'Freight', 'Cargo', 'Material'],
            'installation': ['Installation', 'Install', 'Mounting', 'Assembly'],
            'testing': ['Test', 'Testing', 'Commissioning', 'Startup'],
            'certification': ['Certificate', 'Cert', 'MTC', 'COC', 'Quality']
        }

    def load_scan_results(self) -> bool:
        """ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ"""
        try:
            # ìµœì‹  ìŠ¤ìº” ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
            result_files = list(Path('.').glob('email_scan_results_*.json'))
            if not result_files:
                logger.error("ìŠ¤ìº” ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            latest_file = max(result_files, key=os.path.getctime)
            logger.info(f"ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ: {latest_file}")
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                self.scan_results = json.load(f)
            
            return True
        except Exception as e:
            logger.error(f"ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            return False

    def extract_case_numbers(self, subject: str) -> List[str]:
        """ì´ë©”ì¼ ì œëª©ì—ì„œ HVDC ì¼€ì´ìŠ¤ ë²ˆí˜¸ ì¶”ì¶œ"""
        if not subject:
            return []
        
        case_numbers = []
        subject_str = str(subject).upper()
        
        # íŒ¨í„´ 1: ì™„ì „í•œ HVDC-ADOPT íŒ¨í„´
        pattern1 = re.findall(self.case_patterns['pattern1'], subject_str, re.IGNORECASE)
        for match in pattern1:
            vendor_code = match[0].upper()
            case_num = match[1]
            full_case = f"HVDC-ADOPT-{vendor_code}-{case_num}"
            if full_case not in case_numbers:
                case_numbers.append(full_case)
        
        # íŒ¨í„´ 2: HVDC í”„ë¡œì íŠ¸ ì½”ë“œ íŒ¨í„´
        pattern2 = re.findall(self.case_patterns['pattern2'], subject_str, re.IGNORECASE)
        for match in pattern2:
            site_code = match[0].upper()
            vendor_code = match[1].upper()
            case_num = match[2]
            full_case = f"HVDC-{site_code}-{vendor_code}-{case_num}"
            if full_case not in case_numbers:
                case_numbers.append(full_case)
        
        # íŒ¨í„´ 3: ê´„í˜¸ ì•ˆ ì•½ì‹ íŒ¨í„´
        pattern3_outer = re.findall(self.case_patterns['pattern3_outer'], subject_str)
        for outer_match in pattern3_outer:
            pattern3_inner = re.findall(self.case_patterns['pattern3_inner'], outer_match, re.IGNORECASE)
            for match in pattern3_inner:
                vendor_code = match[0].upper()
                case_num = match[1]
                full_case = f"HVDC-ADOPT-{vendor_code}-{case_num}"
                if full_case not in case_numbers:
                    case_numbers.append(full_case)
        
        # íŒ¨í„´ 4: JPTW/GRM íŒ¨í„´
        pattern4 = re.findall(self.case_patterns['pattern4'], subject_str, re.IGNORECASE)
        for match in pattern4:
            jptw_num = match[1]
            grm_num = match[3]
            full_case = f"HVDC-AGI-JPTW{jptw_num}-GRM{grm_num}".upper()
            if full_case not in case_numbers:
                case_numbers.append(full_case)
        
        # íŒ¨í„´ 5: ì½œë¡  ë’¤ ì™„ì„±í˜• íŒ¨í„´
        pattern5 = re.findall(self.case_patterns['pattern5'], subject_str, re.IGNORECASE)
        for match in pattern5:
            clean_case = re.sub(r'\(.*?\)', '', match).strip().upper()
            if clean_case not in case_numbers:
                case_numbers.append(clean_case)
        
        return case_numbers

    def extract_project_phase(self, subject: str) -> str:
        """ì´ë©”ì¼ ì œëª©ì—ì„œ í”„ë¡œì íŠ¸ ë‹¨ê³„ ì¶”ì¶œ"""
        subject_lower = str(subject).lower()
        
        for phase, keywords in self.project_phases.items():
            for keyword in keywords:
                if keyword.lower() in subject_lower:
                    return phase
        
        return 'general'

    def extract_lpo_numbers(self, subject: str) -> List[str]:
        """LPO ë²ˆí˜¸ ì¶”ì¶œ"""
        lpo_pattern = r'LPO[-\s]?(\d+)'
        matches = re.findall(lpo_pattern, str(subject), re.IGNORECASE)
        return [f"LPO-{m}" for m in matches]

    def extract_site_codes(self, subject: str) -> List[str]:
        """ì‚¬ì´íŠ¸ ì½”ë“œ ì¶”ì¶œ"""
        site_pattern = r'\b(DAS|AGI|MIR|MIRFA|GHALLAN)\b'
        matches = re.findall(site_pattern, str(subject), re.IGNORECASE)
        return [match.upper() for match in matches]

    def build_project_connections(self):
        """í”„ë¡œì íŠ¸ ì—°ê²° ê´€ê³„ êµ¬ì¶•"""
        logger.info("í”„ë¡œì íŠ¸ ì—°ê²° ê´€ê³„ êµ¬ì¶• ì‹œì‘")
        
        for folder_name, folder_data in self.scan_results.get('folders', {}).items():
            if 'emails' not in folder_data:
                continue
            
            for email in folder_data['emails']:
                subject = email.get('subject', '')
                received_time = email.get('received_time', '')
                sender = email.get('sender', '')
                
                # ì¼€ì´ìŠ¤ ë²ˆí˜¸ ì¶”ì¶œ
                cases = self.extract_case_numbers(subject)
                
                # í”„ë¡œì íŠ¸ ë‹¨ê³„ ì¶”ì¶œ
                phase = self.extract_project_phase(subject)
                
                # LPO ë²ˆí˜¸ ì¶”ì¶œ
                lpos = self.extract_lpo_numbers(subject)
                
                # ì‚¬ì´íŠ¸ ì½”ë“œ ì¶”ì¶œ
                sites = self.extract_site_codes(subject)
                
                # íƒ€ì„ë¼ì¸ ë°ì´í„° ì¶”ê°€
                timeline_entry = {
                    'folder': folder_name,
                    'subject': subject,
                    'sender': sender,
                    'received_time': received_time,
                    'cases': cases,
                    'phase': phase,
                    'lpos': lpos,
                    'sites': sites,
                    'file_path': email.get('file_path', '')
                }
                self.timeline_data.append(timeline_entry)
                
                # ì¼€ì´ìŠ¤ë³„ ì—°ê²° ê´€ê³„
                for case in cases:
                    self.case_network[case].append({
                        'folder': folder_name,
                        'subject': subject,
                        'received_time': received_time,
                        'phase': phase
                    })
                
                # ì‚¬ì´íŠ¸ë³„ ì—°ê²° ê´€ê³„
                for site in sites:
                    self.site_network[site].append({
                        'folder': folder_name,
                        'subject': subject,
                        'received_time': received_time,
                        'cases': cases
                    })
                
                # ë²¤ë”ë³„ ì—°ê²° ê´€ê³„
                for case in cases:
                    vendor_match = re.search(r'HVDC-ADOPT-([A-Z]+)-', case)
                    if vendor_match:
                        vendor = vendor_match.group(1)
                        self.vendor_network[vendor].append({
                            'folder': folder_name,
                            'subject': subject,
                            'received_time': received_time,
                            'case': case
                        })

    def generate_comprehensive_report(self) -> str:
        """ì¢…í•© í”„ë¡œì íŠ¸ ì—°ê²° ë³´ê³ ì„œ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ê¸°ë³¸ í†µê³„
        total_emails = len(self.timeline_data)
        total_cases = len(self.case_network)
        total_sites = len(self.site_network)
        total_vendors = len(self.vendor_network)
        
        # ì¼€ì´ìŠ¤ë³„ í†µê³„
        case_stats = {}
        for case, emails in self.case_network.items():
            case_stats[case] = {
                'email_count': len(emails),
                'phases': list(set([e['phase'] for e in emails])),
                'folders': list(set([e['folder'] for e in emails])),
                'date_range': {
                    'earliest': min([e['received_time'] for e in emails if e['received_time']]),
                    'latest': max([e['received_time'] for e in emails if e['received_time']])
                }
            }
        
        # ì‚¬ì´íŠ¸ë³„ í†µê³„
        site_stats = {}
        for site, emails in self.site_network.items():
            site_stats[site] = {
                'email_count': len(emails),
                'case_count': len(set([case for e in emails for case in e['cases']])),
                'folders': list(set([e['folder'] for e in emails])),
                'site_name': self.site_codes.get(site, site)
            }
        
        # ë²¤ë”ë³„ í†µê³„
        vendor_stats = {}
        for vendor, emails in self.vendor_network.items():
            vendor_stats[vendor] = {
                'email_count': len(emails),
                'case_count': len(set([e['case'] for e in emails])),
                'folders': list(set([e['folder'] for e in emails])),
                'vendor_name': self.vendor_codes.get(vendor, vendor)
            }
        
        # í”„ë¡œì íŠ¸ ë‹¨ê³„ë³„ í†µê³„
        phase_stats = defaultdict(int)
        for entry in self.timeline_data:
            phase_stats[entry['phase']] += 1
        
        # ë³´ê³ ì„œ ìƒì„±
        report = f"""
# HVDC í”„ë¡œì íŠ¸ ì¢…í•© ì´ë©”ì¼ ì—°ê²° ë¶„ì„ ë³´ê³ ì„œ
ìƒì„±ì¼ì‹œ: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ğŸ“Š ì „ì²´ í”„ë¡œì íŠ¸ ê°œìš”
- **ì´ ì´ë©”ì¼ ìˆ˜**: {total_emails:,}ê°œ
- **ì´ ì¼€ì´ìŠ¤ ìˆ˜**: {total_cases:,}ê°œ
- **ì´ ì‚¬ì´íŠ¸ ìˆ˜**: {total_sites:,}ê°œ
- **ì´ ë²¤ë” ìˆ˜**: {total_vendors:,}ê°œ

## ğŸ¯ ì¼€ì´ìŠ¤ë³„ ìƒì„¸ ë¶„ì„ (Top 20)
"""
        
        # ì¼€ì´ìŠ¤ë³„ ìƒìœ„ 20ê°œ
        top_cases = sorted(case_stats.items(), key=lambda x: x[1]['email_count'], reverse=True)[:20]
        for case, stats in top_cases:
            report += f"""
### {case}
- **ì´ë©”ì¼ ìˆ˜**: {stats['email_count']}ê°œ
- **ê´€ë ¨ í´ë”**: {', '.join(stats['folders'][:5])}{'...' if len(stats['folders']) > 5 else ''}
- **í”„ë¡œì íŠ¸ ë‹¨ê³„**: {', '.join(stats['phases'])}
- **ê¸°ê°„**: {stats['date_range']['earliest']} ~ {stats['date_range']['latest']}
"""
        
        report += f"""
## ğŸ—ï¸ ì‚¬ì´íŠ¸ë³„ ë¶„ì„
"""
        for site, stats in sorted(site_stats.items(), key=lambda x: x[1]['email_count'], reverse=True):
            report += f"""
### {site} ({stats['site_name']})
- **ì´ë©”ì¼ ìˆ˜**: {stats['email_count']}ê°œ
- **ì¼€ì´ìŠ¤ ìˆ˜**: {stats['case_count']}ê°œ
- **ê´€ë ¨ í´ë”**: {', '.join(stats['folders'][:5])}{'...' if len(stats['folders']) > 5 else ''}
"""
        
        report += f"""
## ğŸ¢ ë²¤ë”ë³„ ë¶„ì„
"""
        for vendor, stats in sorted(vendor_stats.items(), key=lambda x: x[1]['email_count'], reverse=True):
            report += f"""
### {vendor} ({stats['vendor_name']})
- **ì´ë©”ì¼ ìˆ˜**: {stats['email_count']}ê°œ
- **ì¼€ì´ìŠ¤ ìˆ˜**: {stats['case_count']}ê°œ
- **ê´€ë ¨ í´ë”**: {', '.join(stats['folders'][:5])}{'...' if len(stats['folders']) > 5 else ''}
"""
        
        report += f"""
## ğŸ“ˆ í”„ë¡œì íŠ¸ ë‹¨ê³„ë³„ ë¶„í¬
"""
        for phase, count in sorted(phase_stats.items(), key=lambda x: x[1], reverse=True):
            phase_name = {
                'procurement': 'ì¡°ë‹¬',
                'shipping': 'ìš´ì†¡',
                'customs': 'ê´€ì„¸',
                'logistics': 'ë¬¼ë¥˜',
                'installation': 'ì„¤ì¹˜',
                'testing': 'í…ŒìŠ¤íŠ¸',
                'certification': 'ì¸ì¦',
                'general': 'ì¼ë°˜'
            }.get(phase, phase)
            report += f"- **{phase_name}**: {count:,}ê°œ ({count/total_emails*100:.1f}%)\n"
        
        report += f"""
## ğŸ”— í”„ë¡œì íŠ¸ ì—°ê²°ì„± ë¶„ì„

### ì£¼ìš” ì—°ê²° íŒ¨í„´
1. **ì¼€ì´ìŠ¤ ì¤‘ì‹¬ ì—°ê²°**: ê° ì¼€ì´ìŠ¤ë³„ë¡œ ê´€ë ¨ëœ ëª¨ë“  ì´ë©”ì¼ê³¼ í´ë” ì¶”ì 
2. **ì‚¬ì´íŠ¸ ì¤‘ì‹¬ ì—°ê²°**: ê° ì‚¬ì´íŠ¸ë³„ë¡œ ê´€ë ¨ëœ ëª¨ë“  í™œë™ ì¶”ì 
3. **ë²¤ë” ì¤‘ì‹¬ ì—°ê²°**: ê° ë²¤ë”ë³„ë¡œ ê´€ë ¨ëœ ëª¨ë“  ê±°ë˜ ì¶”ì 
4. **ì‹œê°„ ì¤‘ì‹¬ ì—°ê²°**: í”„ë¡œì íŠ¸ ì§„í–‰ ë‹¨ê³„ë³„ ì´ë©”ì¼ íë¦„ ì¶”ì 

### ê¶Œì¥ì‚¬í•­
1. **ë°ì´í„° ì •í•©ì„±**: ë™ì¼ ì¼€ì´ìŠ¤ì˜ ì´ë©”ì¼ë“¤ì´ ì¼ê´€ëœ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
2. **í”„ë¡œì„¸ìŠ¤ ìµœì í™”**: ë¹ˆë²ˆí•œ ì´ë©”ì¼ êµí™˜ì´ ë°œìƒí•˜ëŠ” ë‹¨ê³„ì˜ í”„ë¡œì„¸ìŠ¤ ê°œì„ 
3. **í†µí•© ê´€ë¦¬**: ë¶„ì‚°ëœ í´ë”ì˜ ê´€ë ¨ ì´ë©”ì¼ë“¤ì„ í†µí•© ê´€ë¦¬ ì‹œìŠ¤í…œìœ¼ë¡œ ì—°ê²°
4. **ìë™í™” êµ¬ì¶•**: ë°˜ë³µì ì¸ ì´ë©”ì¼ íŒ¨í„´ì˜ ìë™ ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•
"""
        
        return report

    def create_network_visualization(self):
        """ë„¤íŠ¸ì›Œí¬ ì‹œê°í™” ìƒì„±"""
        logger.info("ë„¤íŠ¸ì›Œí¬ ì‹œê°í™” ìƒì„± ì‹œì‘")
        
        # NetworkX ê·¸ë˜í”„ ìƒì„±
        G = nx.Graph()
        
        # ë…¸ë“œ ì¶”ê°€
        for case in self.case_network.keys():
            G.add_node(case, node_type='case')
        
        for site in self.site_network.keys():
            G.add_node(site, node_type='site')
        
        for vendor in self.vendor_network.keys():
            G.add_node(vendor, node_type='vendor')
        
        # ì—£ì§€ ì¶”ê°€ (ì¼€ì´ìŠ¤-ì‚¬ì´íŠ¸-ë²¤ë” ì—°ê²°)
        for case, emails in self.case_network.items():
            for email in emails:
                # ì¼€ì´ìŠ¤-ì‚¬ì´íŠ¸ ì—°ê²°
                for site in email.get('sites', []):
                    G.add_edge(case, site, weight=1)
                
                # ì¼€ì´ìŠ¤-ë²¤ë” ì—°ê²°
                vendor_match = re.search(r'HVDC-ADOPT-([A-Z]+)-', case)
                if vendor_match:
                    vendor = vendor_match.group(1)
                    G.add_edge(case, vendor, weight=1)
        
        # ì‹œê°í™”
        plt.figure(figsize=(20, 15))
        pos = nx.spring_layout(G, k=3, iterations=50)
        
        # ë…¸ë“œ íƒ€ì…ë³„ ìƒ‰ìƒ
        node_colors = []
        for node in G.nodes():
            if G.nodes[node]['node_type'] == 'case':
                node_colors.append('lightblue')
            elif G.nodes[node]['node_type'] == 'site':
                node_colors.append('lightgreen')
            else:  # vendor
                node_colors.append('lightcoral')
        
        # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        nx.draw(G, pos, 
                node_color=node_colors,
                node_size=500,
                with_labels=True,
                font_size=8,
                font_weight='bold',
                edge_color='gray',
                alpha=0.7)
        
        plt.title('HVDC í”„ë¡œì íŠ¸ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ë„', fontsize=16, fontweight='bold')
        plt.axis('off')
        
        # ë²”ë¡€ ì¶”ê°€
        legend_elements = [
            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightblue', markersize=10, label='ì¼€ì´ìŠ¤'),
            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightgreen', markersize=10, label='ì‚¬ì´íŠ¸'),
            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightcoral', markersize=10, label='ë²¤ë”')
        ]
        plt.legend(handles=legend_elements, loc='upper right')
        
        plt.tight_layout()
        plt.savefig('hvdc_project_network.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info("ë„¤íŠ¸ì›Œí¬ ì‹œê°í™” ì™„ë£Œ: hvdc_project_network.png")

    def save_comprehensive_data(self):
        """ì¢…í•© ë°ì´í„° ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # íƒ€ì„ë¼ì¸ ë°ì´í„° CSV ì €ì¥
        df_timeline = pd.DataFrame(self.timeline_data)
        df_timeline.to_csv(f'hvdc_timeline_data_{timestamp}.csv', index=False, encoding='utf-8-sig')
        
        # ì¼€ì´ìŠ¤ë³„ ìƒì„¸ ë°ì´í„° ì €ì¥
        case_details = []
        for case, emails in self.case_network.items():
            case_details.append({
                'case_number': case,
                'email_count': len(emails),
                'phases': ', '.join(set([e['phase'] for e in emails])),
                'folders': ', '.join(set([e['folder'] for e in emails])),
                'date_range': f"{min([e['received_time'] for e in emails if e['received_time']])} ~ {max([e['received_time'] for e in emails if e['received_time']])}"
            })
        
        df_cases = pd.DataFrame(case_details)
        df_cases = df_cases.sort_values('email_count', ascending=False)
        df_cases.to_csv(f'hvdc_case_analysis_{timestamp}.csv', index=False, encoding='utf-8-sig')
        
        # ì‚¬ì´íŠ¸ë³„ ìƒì„¸ ë°ì´í„° ì €ì¥
        site_details = []
        for site, emails in self.site_network.items():
            site_details.append({
                'site_code': site,
                'site_name': self.site_codes.get(site, site),
                'email_count': len(emails),
                'case_count': len(set([case for e in emails for case in e['cases']])),
                'folders': ', '.join(set([e['folder'] for e in emails]))
            })
        
        df_sites = pd.DataFrame(site_details)
        df_sites = df_sites.sort_values('email_count', ascending=False)
        df_sites.to_csv(f'hvdc_site_analysis_{timestamp}.csv', index=False, encoding='utf-8-sig')
        
        # ë²¤ë”ë³„ ìƒì„¸ ë°ì´í„° ì €ì¥
        vendor_details = []
        for vendor, emails in self.vendor_network.items():
            vendor_details.append({
                'vendor_code': vendor,
                'vendor_name': self.vendor_codes.get(vendor, vendor),
                'email_count': len(emails),
                'case_count': len(set([e['case'] for e in emails])),
                'folders': ', '.join(set([e['folder'] for e in emails]))
            })
        
        df_vendors = pd.DataFrame(vendor_details)
        df_vendors = df_vendors.sort_values('email_count', ascending=False)
        df_vendors.to_csv(f'hvdc_vendor_analysis_{timestamp}.csv', index=False, encoding='utf-8-sig')
        
        # ì¢…í•© ë³´ê³ ì„œ ì €ì¥
        report = self.generate_comprehensive_report()
        with open(f'hvdc_comprehensive_report_{timestamp}.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ì¢…í•© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {timestamp}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    email_root = r"C:/Users/SAMSUNG/Documents/EMAIL"
    
    logger.info("HVDC í”„ë¡œì íŠ¸ ì¢…í•© ì´ë©”ì¼ ë§¤í•‘ ì‹œì‘")
    
    mapper = ComprehensiveEmailMapper(email_root)
    
    try:
        # ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ
        if not mapper.load_scan_results():
            logger.error("ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨")
            return
        
        # í”„ë¡œì íŠ¸ ì—°ê²° ê´€ê³„ êµ¬ì¶•
        mapper.build_project_connections()
        
        # ë„¤íŠ¸ì›Œí¬ ì‹œê°í™” ìƒì„±
        mapper.create_network_visualization()
        
        # ì¢…í•© ë°ì´í„° ì €ì¥
        mapper.save_comprehensive_data()
        
        logger.info("HVDC í”„ë¡œì íŠ¸ ì¢…í•© ì´ë©”ì¼ ë§¤í•‘ ì™„ë£Œ")
        
        # ê°„ë‹¨í•œ ìš”ì•½ ì¶œë ¥
        print(f"\nğŸ¯ HVDC í”„ë¡œì íŠ¸ ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“§ ì´ ì´ë©”ì¼: {len(mapper.timeline_data):,}ê°œ")
        print(f"ğŸ¯ ì´ ì¼€ì´ìŠ¤: {len(mapper.case_network):,}ê°œ")
        print(f"ğŸ—ï¸ ì´ ì‚¬ì´íŠ¸: {len(mapper.site_network):,}ê°œ")
        print(f"ğŸ¢ ì´ ë²¤ë”: {len(mapper.vendor_network):,}ê°œ")
        
    except Exception as e:
        logger.error(f"ì¢…í•© ë§¤í•‘ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()
